colnames(mat_results) <- c("DGP","T","n","$\\Pr(\\Delta\\in \\text{CI}^1_{.95})$","CI$^1$ av. length","$\\Pr(\\Delta\\in \\text{CI}^2_{.95})$", "CI$^2$ av. length")
# xtable(mat_results0)
print(xtable(mat_results,digits=c(0,0,0,0,2,3,2,3)),sanitize.text.function=function(x){x}, include.rownames=FALSE)
dim(mat_estim)
colnames(mat_estim) <- c("DGP","T","n","$\\sigma(\\widehat{\\underline{\\Delta}})$","Bias$(\\widehat{\\underline{\\Delta}})$",
"$\\sigma(\\widehat{\\overline{\\Delta}})$","Bias$(\\widehat{\\overline{\\Delta}})$",
"$\\sigma(\\widehat{\\overline{\\Delta}})$","Bias$(\\widehat{\\overline{\\Delta}})$","$E(\\widehat{\\overline{b}})$")
# xtable(mat_results0)
print(xtable(mat_estim,digits=c(0,0,0,0,3,3,3,3,3,4,4)),sanitize.text.function=function(x){x}, include.rownames=FALSE)
rm(list=ls())
# root = "C:/Users/GAILLAC Christophe/Dropbox/RA_2021/Simulations_r/"
## load libraries
library(MarginalFElogit)
library(R.matlab)
library(pracma)
library(MASS)
# library(admisc)
# library(signal)
# library(RConics)
library(snowfall)
# library(abind)
# library(xtable)
# library(knitr)
# library(dplyr)
# library(kableExtra)
# library(plm)
library(survival)
library(pglm)
library(margins)
library(plm)
#########################################################################################################
###############  Balanced dataset  ######################################################################
#########################################################################################################
data('UnionWage', package = 'pglm')
?UnionWage
UnionWage$union = (UnionWage$union =="yes")*1
UnionWage$rural = (UnionWage$rural =="yes")*1
UnionWage$black = (UnionWage$com =="black")*1 # used as test for discarded variable because constant
UnionWage$NorthEast =(UnionWage$region =="NorthEast")*1
# wage : continuous
# rural,  married : binary
# exper : continuous
sub <- UnionWage[UnionWage$year <1986 ,c("id", "year","exper","married","union","wage","black","NorthEast")]
sub <- as.data.frame(sub)
############## Estimate ##########################################
### formula
formul = as.formula(union ~  exper + married +black )
Option = "sharp"
# Option = "quick"
sub[1,3] <- NA
sub[4,5] <- NA
output <- felogit(formul , data= sub, Option  = Option, compute_T =  NULL)
summary_felogit(output)
60*200
rm(list=ls())
# root = "C:/Users/GAILLAC Christophe/Dropbox/RA_2021/Simulations_r/"
## load libraries
library(MarginalFElogit)
library(R.matlab)
library(pracma)
library(MASS)
# library(admisc)
# library(signal)
# library(RConics)
library(snowfall)
# library(abind)
# library(xtable)
# library(knitr)
# library(dplyr)
# library(kableExtra)
# library(plm)
library(survival)
library(pglm)
library(margins)
library(plm)
#########################################################################################################
###############  Balanced dataset  ######################################################################
#########################################################################################################
data('UnionWage', package = 'pglm')
?UnionWage
UnionWage$union = (UnionWage$union =="yes")*1
UnionWage$rural = (UnionWage$rural =="yes")*1
UnionWage$black = (UnionWage$com =="black")*1 # used as test for discarded variable because constant
UnionWage$NorthEast =(UnionWage$region =="NorthEast")*1
# wage : continuous
# rural,  married : binary
# exper : continuous
sub <- UnionWage[UnionWage$year <1986 ,c("id", "year","exper","married","union","wage","black","NorthEast")]
sub <- as.data.frame(sub)
############## Estimate ##########################################
### formula
formul = as.formula(union ~  exper + married +black )
Option = "sharp"
# Option = "quick"
sub[1,3] <- NA
sub[4,5] <- NA
output <- felogit(formul , data= sub, Option  = Option, compute_T =  "all")
summary_felogit(output)
data= sub
if (is.null(Option)) {
Option  = "quick"
}
if (is.null( compute_X)) {
compute_X = NULL
}
if (is.null( compute_T)) {
compute_T = NULL
}
if (is.null(  cluster)) {
cluster = NULL
}
if (is.null(alpha)) {
alpha = 0.05
}
if (is.null( CIOption)) {
CIOption = "CI2"
}
if (is.null( ratio)) {
ratio = 10
}
compute_X = NULL
cluster = NULL
CIOption = "CI2"
nbCores=4
ratio=10
### first column of data must be individual identifier
var_id = colnames(data)[1]
### second column of data must be periods
var_time =  colnames(data)[2]
### parse formula
l <- as.list(attr(terms(formul), "variables"))[-1]
var_y = as.character(l[[1]])
var_x = matrix(1,1,length(l)-1)
for(i in 1:(length(l)-1)){
var_x[i] = as.character(l[[i+1]])
}
var_x =  c( var_x)
dimX = length(var_x)
### check if non constant variables
vardiscard=NULL
indic = NULL
#i=1
sdna = function(x){return(sd(x,na.rm=TRUE))}
for (i in 1:length(var_x)){
test0 <- quantile(tapply(data[,var_x[i]], data[,var_id], FUN=sdna), 0.99, na.rm=T)
if(test0 ==0){
indic = c(indic, i)
}
}
#i =4
if(!is.null( indic)){
vardiscard=var_x[indic]
var_x = var_x[-c(indic)]
dimX= length(var_x)
}
### cleaning data and tests.
### transformation of the data to wide
### balanced panel with na
s0<- make.pbalanced(data[,c(var_id,var_time,var_y, var_x)], balance.type="fill" )
s0$sumNA <- (rowSums(is.na(s0[,c(var_x ,var_y)]))>0)*1
# stocknb max period
nbmax =  length(unique(s0[,var_time]))
##
# ss <- as.data.frame(s0 %>% group_by("idcode") %>% sum("sumNA"))
ss <- tapply(s0$sumNA, s0[,var_id], FUN=sum)
ss = as.data.frame(cbind(rownames(ss),ss))
colnames(ss ) <- c(var_id,"count_id")
sub_1 = merge(s0[,c(var_id,var_time)],ss,by.x=var_id , by.y =var_id , all.x=TRUE)
## nb of unobserved period  <= nbmax-2 => nb of observed periods >=2
if(max(as.numeric(sub_1$count_id))< (nbmax-1)){
## no attrition
sub_select <- s0
ndiscard = 0
}else{
indic = as.numeric(sub_1$count_id)>=(nbmax-1)
sub_select <- s0[!indic,]
sub_discard <- s0[indic,]
# report number of discarded individuals
ndiscard = length(unique(sub_discard[,var_id]))
}
# record all time labels
times = sort(unique(sub_select[,var_time]))
Tmax = length(times)
### second stage : reshape in wide
sub_wide <- reshape(sub_select[,c(var_id,var_time,var_y, var_x)], idvar = var_id, timevar = var_time, direction = "wide")
nobs = dim(sub_wide)[1]
sub_wide[79,]
labels.x = matrix(NA,dimX,Tmax)
labels.y = matrix(NA,1,Tmax)
for(i in 1:Tmax){
labels.y[i] = paste0(var_y,".",times[i])
for(j in 1:dimX){
labels.x[j,i] = paste0(var_x[j],".",times[i])
}
}
dataX = array(NA,c(dim(sub_wide)[1],Tmax,dimX))
for(j in 1:dimX){
dataX[,,j] = as.matrix(sub_wide[,labels.x[j,]],dim(sub_wide)[1],Tmax)
}
# dim(dataX)
dataY = as.matrix(sub_wide[,labels.y],dim(sub_wide)[1],Tmax)
### handle attrition if any
G_all = (!is.na(dataY))*1
for(j in 1:dimX){
G_all =  G_all*(!is.na(dataX[,,j]))*1
}
# dataY[79,]
## 0 = NA
indic = !duplicated(G_all)
G_types = matrix(G_all[ indic,], sum( indic), dim(G_all)[2])
rownames(G_types) <- 1:dim(G_types)[1]
g_labels = matrix(NA,dim(G_all)[1],1)
# g=1
for(g in 1:dim(G_types)[1]){
g_labels [rowSums(G_all==(matrix(1,dim(G_all)[1],1)%*%matrix(G_types[g,],1, dim(G_types)[2] ))) == dim(G_all)[2]] <- g
}
### transform data.
Xall = array(NA,dim(dataX))
Yall  = array(NA,dim(dataY))
# g=3
for(g in 1:dim(G_types)[1]){
tinf= sum( G_types[g,]==1)
Xall[g_labels==g,1:tinf,]   = dataX[g_labels==g, G_types[g,]==1,]
Yall [g_labels==g,1:tinf]   = dataY[g_labels==g, G_types[g,]==1]
}
if(is.null(cluster)){
Call = NULL
}else{
Call = sub_wide[,c(cluster)]
}
G_indic = G_types*(matrix(1,dim(G_types),1,1)%*%(1:Tmax))
## get the types of the variables
Tinf =  apply(Yall,1,isnot)
Tmax = max(Tinf)
dimX <- dim(Xall)[3]
## default is continuous
type_cont= matrix(1,dimX,1)
# i=1
for (i in 1:dimX){
if(length(table(Xall[,,i]))==2){
type_cont[i] = 0
}
}
ref_c =  (1:dimX)[type_cont==1]
ref_b =  (1:dimX)[type_cont==0]
if(!is.null(var_x)){
var_x_c = var_x[ref_c]
var_x_b = var_x[ref_b]
}else{
var_x_c = NULL
var_x_b = NULL
if(length( ref_c)>0){
for(j in 1:length( ref_c)){
var_x_c = c(var_x_c, paste0("Xc",j))
}
}
if(length( ref_b)>0){
for(j in 1:length( ref_b)){
var_x_b = c(var_x_b, paste0("Xb",j))
}
}
}
if(sum(type_cont==0)>0){
Option = "quick"
#### add warning message
}
if(sum(type_cont)>0){
out_c = compute_AME(Yall,Xall, Call= Call,  Option , selectX = ref_c, compute_T  , alpha , CIOption,  g_labels  , G_types, G_indic, nbCores,ratio )
}
compute_T =  "all"
if(sum(type_cont)>0){
out_c = compute_AME(Yall,Xall, Call= Call,  Option , selectX = ref_c, compute_T  , alpha , CIOption,  g_labels  , G_types, G_indic, nbCores,ratio )
}
sub
selectX = ref_c
Tinf =  apply(Yall,1,isnot)
## Max of the Tinf in dataset
Tmax = max(Tinf)
## Get the dimension of X
if(length(dim(Xall))==3){
dimX = dim(Xall)[3]
}else{
dimX=1
}
### find the distibution of Tinf in the population and sample size
grid_T = NULL
n_dist = NULL
for(t in 1:Tmax){
if(  sum(Tinf==t)>0){
grid_T = c(  grid_T , t)
n_dist = c( n_dist,sum(Tinf==t))
}
}
prop_T = n_dist/sum(n_dist)
## number of clusters
if(is.null(Call)){
Call1 = matrix(1, dim(Yall)[1],1)
}else{
Call1 =  Call
}
## compute combinatorial numbers at all possible dates in the dataset.
mat_C_k_T= vector("list")
cheb_coeff=vector("list")
for(t in 1:length(grid_T)){
T0 = grid_T[t]
M1 = repmat( matrix(seq(0,T0)),1,T0+1) -  repmat(seq(0,T0),T0+1,1)
mat_C_k_T[[T0]]  = choose(repmat(T0-(0:T0),T0+1,1), M1)
cheb_coeff[[T0]]  = fliplr(t(coeff_Cheb01(T0+1)));
}
## consider linear regression est. /4 as starting point
options(warn=-1)
b_lin = optim(par = rep(0,dimX) , lin_reg ,Y=Yall,X=Xall)$par
start_point = b_lin/4
options(warn=0)
# if(dimX==1){
#   b_hat = optimize( log_lik_FE_logit,start_bounds,Y=Yall,X=Xall )$minimum
# }else{
### estimate loglikelihood.
# ** insert catching errors ex: delete constant variables, ect..
options(warn=-1)
b_hat = optim(par = start_point, log_lik_FE_logit,Y=Yall,X=Xall)$par
options(warn=0)
# }
# Compute the influence function of beta_hat. Useful for inference on
# Delta, at the end.
phi_b = infl_func_beta(b_hat,Yall, Xall, Call1);
std_b = apply(phi_b,2,std)/sqrt(dim(phi_b)[1])
##
output = vector("list")
append_name <- function(x){return(paste0("T_",x))}
for(t_end in 1:Tmax){
# find types containing t_end
if(!is.null(G_types)){
sel_g = G_types[,t_end]==1
# discard observations if T not in periods.
Tall = matrix(NA,dim( g_labels)[1],1)
for(g in 1:length( sel_g)){
if( sel_g[g]){
Tall[g_labels==g,1]<-t_end
}
}
}else{
Tall = pmin(t_end,Tinf)
# discard observations if T < t_end
Tall[Tall < t_end] <- NA
}
output[[t_end]] <-  compute_AME_t(Yall,Xall, prop_T,
grid_T,n_dist,Tmax,Tall,Tinf,Call1,mat_C_k_T,
cheb_coeff,b_hat,alpha, CIOption ,Option,dimX,  selectX, phi_b, std_b  , nbCores, ratio)
}
t_end
### parameters for the sharp method.
# ratio=10
RK = 1/(2*sqrt(pi)); #% int K^2(u)du
kappa2 = 1; #% int u^2 K(u)du
c_hat = vector("list")
### number of variables to compute the AME/ATE
if(is.null(selectX)){
nb_var = dimX
selectX = 1:dimX
}else{
nb_var = length(selectX)
}
### to stock the phi_alpha stat.
phi_alpha_m= matrix(NA,nb_var,1)
###
grid_T0 = sort(unique(Tall))
start_time <- Sys.time()
X = array(Xall[!is.na(Tall),,], c(sum(!is.na(Tall)),dim(Xall)[2],dim(Xall)[3]))
Y = matrix(Yall[!is.na(Tall),], sum(!is.na(Tall)), dim(Yall)[2])
Tall0 = Tall[!is.na(Tall)]
Tinf0 = Tinf[!is.na(Tall)]
Call10 = matrix(Call1[!is.na(Tall),], sum(!is.na(Tall)), 1)
grid_T1 = grid_T[grid_T >=min( Tall0 )]
# Tmax = max(grid_T1)
# X = Xall
# Y = Yall
n <- dim(X)[1]
# T <- dim(X)[2]
## stock the sample size
n_s <- n
if(length(dim(X))==3){
dimX = dim(X)[3]
}else{
dimX=1
}
S = apply(Y,1,sumNA)
# dim(  X)
# if( length(dim(X)) ==3){
#   XT =  matrix(X[,Tall,],n,dimX)
# }else{
#   XT = matrix(X[,Tall],n,dimX)
# }
XT =  matrix(NA,n,dimX)
if( length(dim(X)) ==3){
# XT = matrix(X[,Tall,],n,dimX)
for (ti in grid_T0){
if(sum(Tall0==ti)>0){
XT[Tall0==ti,] =  matrix(X[Tall0==ti,ti,],sum(Tall0==ti),dimX)
}
}
}else{
# XT = matrix(X[,Tall],n,dimX)
for (ti in grid_T0){
if(sum(Tall0==ti)>0){
XT[Tall0==ti,] = matrix(X[Tall0==ti,ti],sum(Tall0==ti),dimX)
}
}
}
# Step 1: CMLE
# b_hat = fminunc(@(b) log_lik_FE_logit(b,Y,X), beta0,options);
# if(dim(X)[2]==1){
#   b_hat = optimize( log_lik_FE_logit,start_bounds,Y=Y,X=X)$minimum
# }else{
#   b_hat = optim(par = start_point, log_lik_FE_logit,Y=Y,X=X)$par
# }
# b_hat$par
index = matrix(NA,n,Tmax)
## test if X of dim > 2
if(length(dim(X))==3){
for(ti in grid_T1){
for (t in 1:ti){
index[Tinf0==ti,t] = X[Tinf0==ti,t,]%*%matrix(b_hat);
}
}
}else{
index = X*b_hat;
}
V = exp(index);
Vtilde = matrix(NA,dim(V)[1],dim(V)[2])
for(ti in grid_T1){
Vtilde[Tinf0==ti,] =  V[Tinf0==ti,]/(matrix(V[Tinf0==ti,Tall0[Tinf0==ti]],sum(Tinf0==ti),1)%*%rep(1,dim(V)[2])) #bsxfun(@rdivide,V,V[,T]);
}
Vtilde_min1 =  matrix(NA,dim(V)[1], (Tmax -1) )
# ti=4
for(ti in grid_T1){
if(ti>=2){
ind = 1:ti
Vtilde_min1[Tinf0==ti,1:(ti-1)] =  Vtilde[Tinf0==ti, ind[ind!=Tall0[Tinf0==ti][1]]] - 1;
}
}
out=best_approx_poly(Vtilde_min1,grid_T1,Tinf0);
res = out[[1]]
g= out[[2]]
if(length(dim(X))==2){
Xtilde = X - matrix(XT,n,1)%*%rep(1,dim(X)[2])
}else{
Xtilde = X
for(j in 1:dim(X)[3]){
Xtilde[,,j] = X[,,j] - matrix(XT[,j],n,1)%*%rep(1,dim(X)[2])
}
}
# ti=3
C_S_vec = matrix(NA,n,1)
for(ti in grid_T1){
C_S_vec[Tinf0==ti] = C_S_fun(S[Tinf0==ti],matrix(Vtilde[Tinf0==ti,1:ti], sum(Tinf0==ti) ,ti ));
}
mat_combin = matrix(NA,n,max(grid_T1)+1)
for(ti in grid_T1){
T_minus_t = repmat(ti - (0:ti ),sum(Tinf0==ti),1);
S_minus_t =  matrix(S[Tinf0==ti])%*%rep(1,ti +1) - matrix(rep(1,length(S[Tinf0==ti])))%*%seq(0,ti )  #bsxfun(@minus, S, seq(0,T));
mat_combin[Tinf0==ti,1:(ti+1)] = choose(T_minus_t,S_minus_t)/repmat(matrix(C_S_vec[Tinf0==ti]),1,ti+1);
}
ti
S_minus_t
T_minus_t = repmat(ti - (0:ti ),sum(Tinf0==ti),1);
T_minus_t
grid_T1
ti
T_minus_t = repmat(ti - (0:ti ),sum(Tinf0==ti),1);
Tinf0
Tinf
Yall
Tinf
Tinf0
Tinf
Tall
grid_T
Tall
t_end
grid_T0 = NULL
n_dist0 = NULL
for(t in 1:Tmax){
if(  sum(Tinf[!is.na(Tall)]==t)>0){
grid_T0 = c(  grid_T0 , t)
n_dist0 = c( n_dist0,sum(Tinf[!is.na(Tall)]==t))
}
}
prop_T0 = n_dist0/sum(n_dist0)
output[[t_end]] <-  compute_AME_t(Yall,Xall, prop_T0,
grid_T0,n_dist0,Tmax,Tall,Tinf,Call1,mat_C_k_T,
cheb_coeff,b_hat,alpha, CIOption ,Option,dimX,  selectX, phi_b, std_b  , nbCores, ratio)
library(MarginalFElogit)
library(MarginalFElogit)
library(MarginalFElogit)
library(MarginalFElogit)
library(MarginalFElogit)
MarginalFElogit
?MarginalFElogit
MarginalFElogit?
help(MarginalFElogit)
help(package="MarginalFElogit")
library(MarginalFElogit)
rm(list=ls())
# root = "C:/Users/GAILLAC Christophe/Dropbox/RA_2021/Simulations_r/"
library("devtools")
install_github('MarginalFElogit','cgaillac')
install_github('MarginalFElogit','cgaillac')
## load libraries
library(MarginalFElogit)
install_github('MarginalFElogit','cgaillac')
install_github('MarginalFElogit','cgaillac')
